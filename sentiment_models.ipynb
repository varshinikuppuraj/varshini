{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    "- Unsupervised model\n",
    "- Supervised model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>UserName</th>\n",
       "      <th>Created_Date</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Lower_Case_Reviews</th>\n",
       "      <th>Sentiment_Manual_BP</th>\n",
       "      <th>Sentiment_Manual</th>\n",
       "      <th>Review_Length</th>\n",
       "      <th>DataSource</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Date</th>\n",
       "      <th>Sentiment_Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8/10/2017</td>\n",
       "      <td>Hh</td>\n",
       "      <td>hh</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>2</td>\n",
       "      <td>Google_PlayStore</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8/11/2017</td>\n",
       "      <td>No</td>\n",
       "      <td>no</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>2</td>\n",
       "      <td>Google_PlayStore</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>asadynwa</td>\n",
       "      <td>8/12/2017</td>\n",
       "      <td>@hotstar_helps during paymnt for premium subsc...</td>\n",
       "      <td>@hotstar_helps during paymnt for premium subsc...</td>\n",
       "      <td>Help</td>\n",
       "      <td>Negative</td>\n",
       "      <td>140</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>jineshroxx</td>\n",
       "      <td>8/11/2017</td>\n",
       "      <td>@hotstartweets I am currently on Jio network a...</td>\n",
       "      <td>@hotstartweets i am currently on jio network a...</td>\n",
       "      <td>Help</td>\n",
       "      <td>Negative</td>\n",
       "      <td>140</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>YaminiSachar</td>\n",
       "      <td>8/5/2017</td>\n",
       "      <td>@hotstartweets the episodes of Sarabhai vs Sar...</td>\n",
       "      <td>@hotstartweets the episodes of sarabhai vs sar...</td>\n",
       "      <td>Help</td>\n",
       "      <td>Negative</td>\n",
       "      <td>140</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID      UserName Created_Date  \\\n",
       "0   1           NaN    8/10/2017   \n",
       "1   2           NaN    8/11/2017   \n",
       "2   3      asadynwa    8/12/2017   \n",
       "3   4    jineshroxx    8/11/2017   \n",
       "4   5  YaminiSachar     8/5/2017   \n",
       "\n",
       "                                             Reviews  \\\n",
       "0                                                 Hh   \n",
       "1                                                 No   \n",
       "2  @hotstar_helps during paymnt for premium subsc...   \n",
       "3  @hotstartweets I am currently on Jio network a...   \n",
       "4  @hotstartweets the episodes of Sarabhai vs Sar...   \n",
       "\n",
       "                                  Lower_Case_Reviews Sentiment_Manual_BP  \\\n",
       "0                                                 hh            Negative   \n",
       "1                                                 no            Negative   \n",
       "2  @hotstar_helps during paymnt for premium subsc...                Help   \n",
       "3  @hotstartweets i am currently on jio network a...                Help   \n",
       "4  @hotstartweets the episodes of sarabhai vs sar...                Help   \n",
       "\n",
       "  Sentiment_Manual  Review_Length        DataSource  Year  Month  Date  \\\n",
       "0         Negative              2  Google_PlayStore  2017      8    10   \n",
       "1         Negative              2  Google_PlayStore  2017      8    11   \n",
       "2         Negative            140           Twitter  2017      8    12   \n",
       "3         Negative            140           Twitter  2017      8    11   \n",
       "4         Negative            140           Twitter  2017      8     5   \n",
       "\n",
       "  Sentiment_Polarity  \n",
       "0            Neutral  \n",
       "1            Neutral  \n",
       "2           Negative  \n",
       "3           Positive  \n",
       "4            Neutral  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hotstar_path = 'https://github.com/skathirmani/datasets/raw/master/hotstar.allreviews_Sentiments.csv'\n",
    "hotstar = pd.read_csv(hotstar_path)\n",
    "hotstar.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hotstar.columns\n",
    "custom_stop_words = []\n",
    "common_stop_words = nltk.corpus.stopwords.words('english')\n",
    "stop_words_all = np.hstack([custom_stop_words, common_stop_words])\n",
    "len(stop_words_all)\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5053, 6152)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = hotstar['Reviews']\n",
    "docs = docs.str.lower()\n",
    "docs = docs.str.replace('[^a-z#@ ]', '')\n",
    "docs = docs.str.split(' ')\n",
    "words_rows = docs.tolist()\n",
    "words_all = []\n",
    "words_rows_clean = []\n",
    "docs_clean = []\n",
    "for row in words_rows:\n",
    "    row_words = [stemmer.stem(word) for word in row if word not in stop_words_all]  \n",
    "    words_rows_clean.append(row_words)\n",
    "    docs_clean.append(' '.join(row_words))\n",
    "    words_all.extend(row_words)\n",
    "\n",
    "    \n",
    "model_dtm = CountVectorizer()\n",
    "sparse_matrix = model_dtm.fit_transform(docs_clean)\n",
    "dtm = pd.DataFrame(sparse_matrix.toarray(),\n",
    "                   columns=model_dtm.get_feature_names())\n",
    "dtm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_x, test_x = train_test_split(dtm, test_size=0.2, random_state=0)\n",
    "\n",
    "train_y = hotstar.iloc[train_x.index]['Sentiment_Manual']\n",
    "test_y = hotstar.iloc[test_x.index]['Sentiment_Manual']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_y.value_counts() / test_y.shape[0] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_y.value_counts() / train_y.shape[0] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\New folder (3)\\anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf = RandomForestClassifier()\n",
    "model_rf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y_rf = model_rf.predict(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72.89812067260138"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(test_y == test_y_rf).sum() / test_y.shape[0] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\New folder (3)\\anaconda\\lib\\site-packages\\nltk\\twitter\\__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "55.78635014836796"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "senti = SentimentIntensityAnalyzer()\n",
    "hotstar['sentiment_vader'] = hotstar['Reviews'].apply(lambda v: \n",
    "                                                      senti.polarity_scores(v)['compound'])\n",
    "def assign_sentiment(v):\n",
    "    if v > 0.25:\n",
    "        return 'Positive'\n",
    "    elif v < -0.25:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "hotstar['sentiment_vader'] = hotstar['sentiment_vader'].apply(assign_sentiment)\n",
    "test_hotstar = hotstar.iloc[test_y.index]\n",
    "(test_hotstar['Sentiment_Manual'] == \n",
    " test_hotstar['sentiment_vader']).sum() / test_hotstar.shape[0] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68.34817012858556"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "model = AdaBoostClassifier()\n",
    "model.fit(train_x, train_y)\n",
    "test_y_pred = model.predict(test_x)\n",
    "(test_y_pred == test_y).sum() / test_y.shape[0] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62.710187932739856"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "model = GaussianNB()\n",
    "model.fit(train_x, train_y)\n",
    "test_y_pred = model.predict(test_x)\n",
    "(test_y_pred == test_y).sum() / test_y.shape[0] * 100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
